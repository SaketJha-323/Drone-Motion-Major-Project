{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the calibrated drone data\n",
    "file_path = 'data/raw/Drone_CoD.csv'\n",
    "drone_data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the columns are named correctly: 'Frame', 'Time', 'X', 'Y', 'Z'\n",
    "drone_data.columns = ['Frame', 'Time', 'X', 'Y', 'Z']\n",
    "\n",
    "# Convert data to numpy array for easier manipulation\n",
    "frames = drone_data['Frame'].values\n",
    "times = drone_data['Time'].values\n",
    "x = drone_data['X'].values / 100  # Convert from mm to meters\n",
    "y = drone_data['Y'].values / 100  # Convert from mm to meters\n",
    "z = drone_data['Z'].values / 100  # Convert from mm to meters\n",
    "\n",
    "# Function to calculate velocity\n",
    "def calculate_velocity(x, times):\n",
    "    return np.diff(x) / np.diff(times)\n",
    "\n",
    "# Function to calculate acceleration\n",
    "def calculate_acceleration(vx, times):\n",
    "    return np.diff(vx) / np.diff(times[1:])\n",
    "\n",
    "# Calculate velocities\n",
    "vx = calculate_velocity(x, times)\n",
    "vy = calculate_velocity(y, times)\n",
    "vz = calculate_velocity(z, times)\n",
    "\n",
    "# Calculate accelerations\n",
    "ax = calculate_acceleration(vx, times)\n",
    "ay = calculate_acceleration(vy, times)\n",
    "az = calculate_acceleration(vz, times)\n",
    "\n",
    "# Ensure all arrays are the same size by trimming\n",
    "min_length = min(len(vx), len(vy), len(vz), len(ax), len(ay), len(az))\n",
    "vx, vy, vz = vx[:min_length], vy[:min_length], vz[:min_length]\n",
    "ax, ay, az = ax[:min_length], ay[:min_length], az[:min_length]\n",
    "\n",
    "# Combine velocities and accelerations into a single array for anomaly detection\n",
    "motion_data = np.vstack((vx, vy, vz, ax, ay, az)).T\n",
    "\n",
    "# Normalize the data for Isolation Forest\n",
    "scaler = StandardScaler()\n",
    "motion_data_scaled = scaler.fit_transform(motion_data)\n",
    "\n",
    "# Apply Isolation Forest for anomaly detection\n",
    "isolation_forest = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
    "anomaly_scores = isolation_forest.fit_predict(motion_data_scaled)\n",
    "\n",
    "# Find indices of anomalies\n",
    "anomaly_indices = np.where(anomaly_scores == -1)[0]\n",
    "\n",
    "# Explanation of anomalies\n",
    "def explain_anomalies(anomaly_indices, vx, vy, vz, ax, ay, az):\n",
    "    anomalies = []\n",
    "    for idx in anomaly_indices:\n",
    "        anomaly_desc = f\"Anomaly at index {idx}: \"\n",
    "        if abs(vx[idx]) > np.mean(vx) + 2 * np.std(vx):\n",
    "            anomaly_desc += f\"Vx ({vx[idx]:.2f}) is abnormally high; \"\n",
    "        if abs(vy[idx]) > np.mean(vy) + 2 * np.std(vy):\n",
    "            anomaly_desc += f\"Vy ({vy[idx]:.2f}) is abnormally high; \"\n",
    "        if abs(vz[idx]) > np.mean(vz) + 2 * np.std(vz):\n",
    "            anomaly_desc += f\"Vz ({vz[idx]:.2f}) is abnormally high; \"\n",
    "        if abs(ax[idx]) > np.mean(ax) + 2 * np.std(ax):\n",
    "            anomaly_desc += f\"Ax ({ax[idx]:.2f}) is abnormally high; \"\n",
    "        if abs(ay[idx]) > np.mean(ay) + 2 * np.std(ay):\n",
    "            anomaly_desc += f\"Ay ({ay[idx]:.2f}) is abnormally high; \"\n",
    "        if abs(az[idx]) > np.mean(az) + 2 * np.std(az):\n",
    "            anomaly_desc += f\"Az ({az[idx]:.2f}) is abnormally high; \"\n",
    "        anomalies.append(anomaly_desc.strip())\n",
    "    return anomalies\n",
    "\n",
    "# Generate anomaly explanations\n",
    "anomaly_explanations = explain_anomalies(anomaly_indices, vx, vy, vz, ax, ay, az)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot position data with anomalies highlighted\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(x[:-2], label='X Position')\n",
    "plt.scatter(anomaly_indices, x[anomaly_indices], color='red', label='Anomalies')\n",
    "plt.legend()\n",
    "plt.title('Position with Anomalies (X)')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(y[:-2], label='Y Position')\n",
    "plt.scatter(anomaly_indices, y[anomaly_indices], color='red', label='Anomalies')\n",
    "plt.legend()\n",
    "plt.title('Position with Anomalies (Y)')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(z[:-2], label='Z Position')\n",
    "plt.scatter(anomaly_indices, z[anomaly_indices], color='red', label='Anomalies')\n",
    "plt.legend()\n",
    "plt.title('Position with Anomalies (Z)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detected anomalies and explanations\n",
    "print(\"Anomalies detected at indices:\", anomaly_indices)\n",
    "for explanation in anomaly_explanations:\n",
    "    print(explanation)\n",
    "\n",
    "# Print average velocity and acceleration\n",
    "print(f\"\\nAverage Velocity: Vx = {np.mean(vx):.2f} m/s, Vy = {np.mean(vy):.2f} m/s, Vz = {np.mean(vz):.2f} m/s\")\n",
    "print(f\"Average Acceleration: Ax = {np.mean(ax):.2f} m/s^2, Ay = {np.mean(ay):.2f} m/s^2, Az = {np.mean(az):.2f} m/s^2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the calibrated drone data\n",
    "file_path = 'data/raw/Drone_CoD.csv'  # Your file path\n",
    "drone_data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the columns are named correctly: 'Frame', 'Time', 'X', 'Y', 'Z'\n",
    "drone_data.columns = ['Frame', 'Time', 'X', 'Y', 'Z']\n",
    "\n",
    "# Convert data to numpy array for easier manipulation\n",
    "frames = drone_data['Frame'].values\n",
    "times = drone_data['Time'].values\n",
    "x = drone_data['X'].values / 100  # Convert from mm to meters\n",
    "y = drone_data['Y'].values / 100  # Convert from mm to meters\n",
    "z = drone_data['Z'].values / 100  # Convert from mm to meters\n",
    "\n",
    "# Function to calculate velocity\n",
    "def calculate_velocity(x, times):\n",
    "    return np.diff(x) / np.diff(times)\n",
    "\n",
    "# Function to calculate acceleration\n",
    "def calculate_acceleration(vx, times):\n",
    "    return np.diff(vx) / np.diff(times[1:])\n",
    "\n",
    "# Calculate velocities\n",
    "vx = calculate_velocity(x, times)\n",
    "vy = calculate_velocity(y, times)\n",
    "vz = calculate_velocity(z, times)\n",
    "\n",
    "# Calculate accelerations\n",
    "ax = calculate_acceleration(vx, times)\n",
    "ay = calculate_acceleration(vy, times)\n",
    "az = calculate_acceleration(vz, times)\n",
    "\n",
    "# Ensure all arrays are the same size by trimming\n",
    "min_length = min(len(vx), len(vy), len(vz), len(ax), len(ay), len(az))\n",
    "vx, vy, vz = vx[:min_length], vy[:min_length], vz[:min_length]\n",
    "ax, ay, az = ax[:min_length], ay[:min_length], az[:min_length]\n",
    "\n",
    "# Combine velocities and accelerations into a single array for anomaly detection\n",
    "motion_data = np.vstack((vx, vy, vz, ax, ay, az)).T\n",
    "\n",
    "# Normalize the data for One-Class SVM\n",
    "scaler = StandardScaler()\n",
    "motion_data_scaled = scaler.fit_transform(motion_data)\n",
    "\n",
    "# Apply One-Class SVM for anomaly detection\n",
    "one_class_svm = OneClassSVM(kernel='rbf', gamma='auto', nu=0.05)  # nu controls the proportion of outliers\n",
    "anomaly_scores = one_class_svm.fit_predict(motion_data_scaled)\n",
    "\n",
    "# Find indices of anomalies\n",
    "anomaly_indices = np.where(anomaly_scores == -1)[0]\n",
    "\n",
    "# Explanation of anomalies\n",
    "def explain_anomalies(anomaly_indices, vx, vy, vz, ax, ay, az):\n",
    "    anomalies = []\n",
    "    for idx in anomaly_indices:\n",
    "        anomaly_desc = f\"Anomaly at index {idx}: \"\n",
    "        if abs(vx[idx]) > np.mean(vx) + 2 * np.std(vx):\n",
    "            anomaly_desc += f\"Vx ({vx[idx]:.2f}) is abnormally high; \"\n",
    "        if abs(vy[idx]) > np.mean(vy) + 2 * np.std(vy):\n",
    "            anomaly_desc += f\"Vy ({vy[idx]:.2f}) is abnormally high; \"\n",
    "        if abs(vz[idx]) > np.mean(vz) + 2 * np.std(vz):\n",
    "            anomaly_desc += f\"Vz ({vz[idx]:.2f}) is abnormally high; \"\n",
    "        if abs(ax[idx]) > np.mean(ax) + 2 * np.std(ax):\n",
    "            anomaly_desc += f\"Ax ({ax[idx]:.2f}) is abnormally high; \"\n",
    "        if abs(ay[idx]) > np.mean(ay) + 2 * np.std(ay):\n",
    "            anomaly_desc += f\"Ay ({ay[idx]:.2f}) is abnormally high; \"\n",
    "        if abs(az[idx]) > np.mean(az) + 2 * np.std(az):\n",
    "            anomaly_desc += f\"Az ({az[idx]:.2f}) is abnormally high; \"\n",
    "        anomalies.append(anomaly_desc.strip())\n",
    "    return anomalies\n",
    "\n",
    "# Generate anomaly explanations\n",
    "anomaly_explanations = explain_anomalies(anomaly_indices, vx, vy, vz, ax, ay, az)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot position data with anomalies highlighted\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(x[:-2], label='X Position')\n",
    "plt.scatter(anomaly_indices, x[anomaly_indices], color='red', label='Anomalies')\n",
    "plt.legend()\n",
    "plt.title('Position with Anomalies (X)')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(y[:-2], label='Y Position')\n",
    "plt.scatter(anomaly_indices, y[anomaly_indices], color='red', label='Anomalies')\n",
    "plt.legend()\n",
    "plt.title('Position with Anomalies (Y)')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(z[:-2], label='Z Position')\n",
    "plt.scatter(anomaly_indices, z[anomaly_indices], color='red', label='Anomalies')\n",
    "plt.legend()\n",
    "plt.title('Position with Anomalies (Z)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detected anomalies and explanations\n",
    "print(\"Anomalies detected at indices:\", anomaly_indices)\n",
    "for explanation in anomaly_explanations:\n",
    "    print(explanation)\n",
    "\n",
    "# Print average velocity and acceleration\n",
    "print(f\"\\nAverage Velocity: Vx = {np.mean(vx):.2f} m/s, Vy = {np.mean(vy):.2f} m/s, Vz = {np.mean(vz):.2f} m/s\")\n",
    "print(f\"Average Acceleration: Ax = {np.mean(ax):.2f} m/s^2, Ay = {np.mean(ay):.2f} m/s^2, Az = {np.mean(az):.2f} m/s^2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "import matplotlib.pyplot as plt\n",
    "from keras._tf_keras.keras.models import Model\n",
    "from keras._tf_keras.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras._tf_keras.keras.optimizers import Adam\n",
    "from keras._tf_keras.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the calibrated drone data\n",
    "file_path = 'data/raw/Drone_CoD.csv'  # Your file path\n",
    "drone_data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the columns are named correctly: 'Frame', 'Time', 'X', 'Y', 'Z'\n",
    "drone_data.columns = ['Frame', 'Time', 'X', 'Y', 'Z']\n",
    "\n",
    "# Convert data to numpy array for easier manipulation\n",
    "frames = drone_data['Frame'].values\n",
    "times = drone_data['Time'].values\n",
    "x = drone_data['X'].values / 100  # Convert from mm to meters\n",
    "y = drone_data['Y'].values / 100  # Convert from mm to meters\n",
    "z = drone_data['Z'].values / 100  # Convert from mm to meters\n",
    "\n",
    "# Function to calculate velocity\n",
    "def calculate_velocity(coord, times):\n",
    "    return np.diff(coord) / np.diff(times)\n",
    "\n",
    "# Function to calculate acceleration\n",
    "def calculate_acceleration(velocity, times):\n",
    "    return np.diff(velocity) / np.diff(times[1:])\n",
    "\n",
    "# Calculate velocities\n",
    "vx = calculate_velocity(x, times)\n",
    "vy = calculate_velocity(y, times)\n",
    "vz = calculate_velocity(z, times)\n",
    "\n",
    "# Calculate accelerations\n",
    "ax = calculate_acceleration(vx, times)\n",
    "ay = calculate_acceleration(vy, times)\n",
    "az = calculate_acceleration(vz, times)\n",
    "\n",
    "# Ensure all arrays are the same size by trimming\n",
    "min_length = min(len(vx), len(vy), len(vz), len(ax), len(ay), len(az))\n",
    "vx, vy, vz = vx[:min_length], vy[:min_length], vz[:min_length]\n",
    "ax, ay, az = ax[:min_length], ay[:min_length], az[:min_length]\n",
    "\n",
    "# Combine velocities and accelerations into a single array for anomaly detection\n",
    "motion_data = np.vstack((vx, vy, vz, ax, ay, az)).T\n",
    "\n",
    "# Create a placeholder for the ground truth array\n",
    "num_samples = motion_data.shape[0]\n",
    "y_true = np.random.choice([0, 1], size=(num_samples,), p=[0.9, 0.1])  # Example ground truth\n",
    "\n",
    "# Step 1: Scale the data\n",
    "scaler = StandardScaler()\n",
    "motion_data_scaled = scaler.fit_transform(motion_data)\n",
    "\n",
    "# Step 2: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(motion_data_scaled, y_true, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Fit Isolation Forest Model\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "iso_forest.fit(X_train)\n",
    "\n",
    "# Predict anomalies\n",
    "y_pred_iso = iso_forest.predict(X_test)\n",
    "y_pred_iso = np.where(y_pred_iso == -1, 1, 0)  # Map -1 to 1 (anomaly), 1 to 0 (normal)\n",
    "\n",
    "# Step 4: Fit One-Class SVM Model\n",
    "svm = OneClassSVM(kernel='rbf', gamma='scale', nu=0.1)\n",
    "svm.fit(X_train)\n",
    "\n",
    "# Predict anomalies\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "y_pred_svm = np.where(y_pred_svm == -1, 1, 0)  # Map -1 to 1 (anomaly), 1 to 0 (normal)\n",
    "\n",
    "# Step 5: Fit Autoencoder Model\n",
    "input_dim = motion_data_scaled.shape[1]  # Number of features\n",
    "encoding_dim = 3  # Adjust as needed\n",
    "\n",
    "# Define the Autoencoder architecture\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# Create the Autoencoder model\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Train the Autoencoder\n",
    "autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, shuffle=True, validation_split=0.2)\n",
    "\n",
    "# Step 6: Make predictions with the Autoencoder\n",
    "predictions = autoencoder.predict(X_test)\n",
    "\n",
    "# Compute reconstruction error\n",
    "reconstruction_error = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "\n",
    "# Set a threshold for anomalies (e.g., 95th percentile)\n",
    "threshold = np.percentile(reconstruction_error, 95)\n",
    "y_pred_autoencoder = [1 if e > threshold else 0 for e in reconstruction_error]\n",
    "\n",
    "# Step 7: Evaluate the models\n",
    "print(\"Isolation Forest Metrics:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_iso))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_iso))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_iso))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_iso))\n",
    "\n",
    "print(\"\\nOne-Class SVM Metrics:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_svm))\n",
    "\n",
    "print(\"\\nAutoencoder Metrics:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_autoencoder))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_autoencoder))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_autoencoder))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_autoencoder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Camera calibration parameters for each camera\n",
    "fx1, fy1 = 700, 700  # Focal lengths for the front camera\n",
    "cx1, cy1 = 320, 240  # Principal points for the front camera\n",
    "fx2, fy2 = 700, 700  # Focal lengths for the side camera\n",
    "cx2, cy2 = 320, 240  # Principal points for the side camera\n",
    "\n",
    "baseline = 1000  # Distance between the two cameras in mm (baseline for triangulation)\n",
    "\n",
    "# Conversion factors for pixel to mm conversion (based on calibration)\n",
    "conversion_factor_x_front = 1 / fx1\n",
    "conversion_factor_y_front = 1 / fy1\n",
    "conversion_factor_x_side = 1 / fx2\n",
    "conversion_factor_y_side = 1 / fy2\n",
    "\n",
    "# Open video files or cameras\n",
    "cap_front = cv2.VideoCapture('data/video/Drone2.mp4')\n",
    "cap_side = cv2.VideoCapture('data/video/Drone1.mp4')\n",
    "\n",
    "# Initialize variables\n",
    "previous_position = None\n",
    "previous_time = None\n",
    "trajectory_data = []\n",
    "\n",
    "def calculate_3d_position(x1, y1, x2):\n",
    "    \"\"\"Calculate 3D position using triangulation based on the front and side view coordinates.\"\"\"\n",
    "    disparity = abs(x1 - x2)\n",
    "    z = fx1 * baseline / disparity if disparity != 0 else 0\n",
    "    x_mm = (x1 - cx1) * conversion_factor_x_front * z\n",
    "    y_mm = (y1 - cy1) * conversion_factor_y_front * z\n",
    "    return np.array([x_mm, y_mm, z])\n",
    "\n",
    "def calculate_velocity_acceleration(new_position, previous_position, dt):\n",
    "    \"\"\"Calculate velocity and acceleration vectors.\"\"\"\n",
    "    velocity = (new_position - previous_position) / dt\n",
    "    if len(trajectory_data) > 1:\n",
    "        prev_velocity = trajectory_data[-1]['velocity']\n",
    "        acceleration = (velocity - prev_velocity) / dt\n",
    "    else:\n",
    "        acceleration = np.array([0, 0, 0])\n",
    "    return velocity, acceleration\n",
    "\n",
    "# Specify the path where the CSV file will be created\n",
    "csv_file_path = 'C:/Users/SAKET JHA/Desktop/Drone_Motion_Data/trajectory_data.csv'\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(os.path.dirname(csv_file_path), exist_ok=True)\n",
    "\n",
    "# Open a CSV file to overwrite the previous data\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Timestamp\", \"X (mm)\", \"Y (mm)\", \"Z (mm)\", \"Velocity (mm/s)\", \"Acceleration (mm/s²)\"])\n",
    "\n",
    "    while cap_front.isOpened() and cap_side.isOpened():\n",
    "        ret1, frame1 = cap_front.read()\n",
    "        ret2, frame2 = cap_side.read()\n",
    "\n",
    "        if not ret1 or not ret2:\n",
    "            break\n",
    "\n",
    "        # Resize frames for easier viewing if needed\n",
    "        frame1 = cv2.resize(frame1, (640, 480))\n",
    "        frame2 = cv2.resize(frame2, (640, 480))\n",
    "\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Simple thresholding for drone detection (replace with actual method if possible)\n",
    "        ret1, thresh1 = cv2.threshold(gray1, 127, 255, cv2.THRESH_BINARY)\n",
    "        ret2, thresh2 = cv2.threshold(gray2, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        contours1, _ = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours2, _ = cv2.findContours(thresh2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if contours1 and contours2:\n",
    "            largest_contour1 = max(contours1, key=cv2.contourArea)\n",
    "            largest_contour2 = max(contours2, key=cv2.contourArea)\n",
    "\n",
    "            x1, y1, w1, h1 = cv2.boundingRect(largest_contour1)\n",
    "            x2, y2, w2, h2 = cv2.boundingRect(largest_contour2)\n",
    "\n",
    "            position = calculate_3d_position(x1 + w1 // 2, y1 + h1 // 2, x2 + w2 // 2)\n",
    "\n",
    "            current_time = time.time()\n",
    "            if previous_time:\n",
    "                dt = current_time - previous_time\n",
    "            else:\n",
    "                dt = 0\n",
    "            previous_time = current_time\n",
    "\n",
    "            if previous_position is not None:\n",
    "                velocity, acceleration = calculate_velocity_acceleration(position, previous_position, dt)\n",
    "            else:\n",
    "                velocity, acceleration = np.array([0, 0, 0]), np.array([0, 0, 0])\n",
    "\n",
    "            # Write the data point to the CSV file, overwriting previous data\n",
    "            writer.writerow([current_time, position[0], position[1], position[2], np.linalg.norm(velocity), np.linalg.norm(acceleration)])\n",
    "\n",
    "            previous_position = position\n",
    "\n",
    "            # Draw bounding boxes\n",
    "            cv2.rectangle(frame1, (x1, y1), (x1 + w1, y1 + h1), (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame2, (x2, y2), (x2 + w2, y2 + h2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame1, f\"3D Position (mm): {position}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow('Front View Tracking', frame1)\n",
    "        cv2.imshow('Side View Tracking', frame2)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap_front.release()\n",
    "cap_side.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Data extraction complete. Data saved to '{csv_file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the video file\n",
    "video_path = 'data/video/Drone2.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit()\n",
    "\n",
    "# Initialize the tracker\n",
    "# For OpenCV 4.5 and newer, use the cv2.legacy module if needed\n",
    "try:\n",
    "    tracker = cv2.TrackerMIL_create()  # Ensure this method is available in your version\n",
    "except AttributeError:\n",
    "    print(\"TrackerMIL_create() method is not available. Try using an alternative tracker.\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    exit()\n",
    "\n",
    "# Read the first frame\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to grab frame\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    exit()\n",
    "\n",
    "# Define the initial bounding box\n",
    "# If cv2.selectROI() is not working, you can manually define bbox\n",
    "bbox = (100, 100, 200, 200)  # Example: (x, y, width, height)\n",
    "# Uncomment the following line if you want to use GUI ROI selection\n",
    "# bbox = cv2.selectROI(frame, False)\n",
    "\n",
    "# Initialize the tracker with the first frame and bounding box\n",
    "tracker.init(frame, bbox)\n",
    "\n",
    "# Variables to store data\n",
    "frame_numbers = []\n",
    "x_positions = []\n",
    "y_positions = []\n",
    "\n",
    "# Process video frames\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Update the tracker\n",
    "    success, bbox = tracker.update(frame)\n",
    "    \n",
    "    if success:\n",
    "        # Extract the center of the bounding box as the object's position\n",
    "        x_center = int(bbox[0] + bbox[2] / 2)\n",
    "        y_center = int(bbox[1] + bbox[3] / 2)\n",
    "        frame_numbers.append(frame_count)\n",
    "        x_positions.append(x_center)\n",
    "        y_positions.append(y_center)\n",
    "    \n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Plotting the extracted data\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot X and Y positions\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(frame_numbers, x_positions, label='X Position', color='blue')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.ylabel('X Position (pixels)')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(frame_numbers, y_positions, label='Y Position', color='red')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.ylabel('Y Position (pixels)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Camera calibration parameters for each camera\n",
    "# Replace these with actual values obtained from camera calibration\n",
    "fx1, fy1 = 700, 700  # Focal lengths for the front camera\n",
    "cx1, cy1 = 320, 240  # Principal points for the front camera\n",
    "fx2, fy2 = 700, 700  # Focal lengths for the side camera\n",
    "cx2, cy2 = 320, 240  # Principal points for the side camera\n",
    "\n",
    "baseline = 1000  # Distance between the two cameras in mm (baseline for triangulation)\n",
    "\n",
    "# Conversion factors for pixel to mm conversion (based on calibration)\n",
    "conversion_factor_x_front = 1 / fx1\n",
    "conversion_factor_y_front = 1 / fy1\n",
    "conversion_factor_x_side = 1 / fx2\n",
    "conversion_factor_y_side = 1 / fy2\n",
    "\n",
    "# Open video files or cameras\n",
    "cap_front = cv2.VideoCapture('data/video/Drone2.mp4')\n",
    "cap_side = cv2.VideoCapture('data/video/Drone1.mp4')\n",
    "\n",
    "# Initialize variables\n",
    "previous_position = None\n",
    "previous_time = None\n",
    "trajectory_data = []\n",
    "\n",
    "def calculate_3d_position(x1, y1, x2):\n",
    "    \"\"\"Calculate 3D position using triangulation based on the front and side view coordinates.\"\"\"\n",
    "    disparity = abs(x1 - x2)\n",
    "    z = fx1 * baseline / disparity if disparity != 0 else 0\n",
    "    x_mm = (x1 - cx1) * conversion_factor_x_front * z\n",
    "    y_mm = (y1 - cy1) * conversion_factor_y_front * z\n",
    "    return np.array([x_mm, y_mm, z])\n",
    "\n",
    "def calculate_velocity_acceleration(new_position, previous_position, dt):\n",
    "    \"\"\"Calculate velocity and acceleration vectors.\"\"\"\n",
    "    velocity = (new_position - previous_position) / dt\n",
    "    if len(trajectory_data) > 1:\n",
    "        prev_velocity = trajectory_data[-1]['velocity']\n",
    "        acceleration = (velocity - prev_velocity) / dt\n",
    "    else:\n",
    "        acceleration = np.array([0, 0, 0])\n",
    "    return velocity, acceleration\n",
    "\n",
    "while cap_front.isOpened() and cap_side.isOpened():\n",
    "    ret1, frame1 = cap_front.read()\n",
    "    ret2, frame2 = cap_side.read()\n",
    "\n",
    "    if not ret1 or not ret2:\n",
    "        break\n",
    "\n",
    "    # Resize frames for easier viewing if needed\n",
    "    frame1 = cv2.resize(frame1, (640, 480))\n",
    "    frame2 = cv2.resize(frame2, (640, 480))\n",
    "\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Simple thresholding for drone detection (replace with actual method if possible)\n",
    "    ret1, thresh1 = cv2.threshold(gray1, 127, 255, cv2.THRESH_BINARY)\n",
    "    ret2, thresh2 = cv2.threshold(gray2, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    contours1, _ = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours2, _ = cv2.findContours(thresh2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours1 and contours2:\n",
    "        largest_contour1 = max(contours1, key=cv2.contourArea)\n",
    "        largest_contour2 = max(contours2, key=cv2.contourArea)\n",
    "\n",
    "        x1, y1, w1, h1 = cv2.boundingRect(largest_contour1)\n",
    "        x2, y2, w2, h2 = cv2.boundingRect(largest_contour2)\n",
    "\n",
    "        position = calculate_3d_position(x1 + w1 // 2, y1 + h1 // 2, x2 + w2 // 2)\n",
    "\n",
    "        current_time = time.time()\n",
    "        if previous_time:\n",
    "            dt = current_time - previous_time\n",
    "        else:\n",
    "            dt = 0\n",
    "        previous_time = current_time\n",
    "\n",
    "        if previous_position is not None:\n",
    "            velocity, acceleration = calculate_velocity_acceleration(position, previous_position, dt)\n",
    "        else:\n",
    "            velocity, acceleration = np.array([0, 0, 0]), np.array([0, 0, 0])\n",
    "\n",
    "        trajectory_data.append({\n",
    "            'position': position,\n",
    "            'velocity': velocity,\n",
    "            'acceleration': acceleration,\n",
    "            'timestamp': current_time\n",
    "        })\n",
    "\n",
    "        previous_position = position\n",
    "\n",
    "        # Draw bounding boxes\n",
    "        cv2.rectangle(frame1, (x1, y1), (x1 + w1, y1 + h1), (0, 255, 0), 2)\n",
    "        cv2.rectangle(frame2, (x2, y2), (x2 + w2, y2 + h2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame1, f\"3D Position (mm): {position}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow('Front View Tracking', frame1)\n",
    "    cv2.imshow('Side View Tracking', frame2)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap_front.release()\n",
    "cap_side.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Analyze trajectory data for anomalies or deviations\n",
    "positions = np.array([data['position'] for data in trajectory_data])\n",
    "\n",
    "# Smooth trajectory data\n",
    "smoothed_positions = savgol_filter(positions, window_length=5, polyorder=2, axis=0)\n",
    "\n",
    "# Calculate deviations (anomalies)\n",
    "deviation = np.linalg.norm(positions - smoothed_positions, axis=1)\n",
    "threshold = 50  # Static threshold in mm for anomaly detection\n",
    "anomalies = deviation > threshold\n",
    "anomaly_indices = np.where(anomalies)[0]\n",
    "\n",
    "print(\"Trajectory Analysis Complete.\")\n",
    "print(\"Detected Anomalies at Frames:\", anomaly_indices)\n",
    "\n",
    "# Explain anomalies based on velocity, acceleration, and position deviation\n",
    "for idx in anomaly_indices:\n",
    "    position_deviation = deviation[idx]\n",
    "    velocity = trajectory_data[idx]['velocity']\n",
    "    acceleration = trajectory_data[idx]['acceleration']\n",
    "    \n",
    "    explanation = f\"Anomaly detected at frame {idx}:\\n\"\n",
    "    explanation += f\"  - Deviation from smoothed path: {position_deviation:.2f} mm\\n\"\n",
    "    explanation += f\"  - Velocity: {np.linalg.norm(velocity):.2f} mm/s\\n\"\n",
    "    explanation += f\"  - Acceleration: {np.linalg.norm(acceleration):.2f} mm/s²\\n\"\n",
    "    \n",
    "    if np.linalg.norm(velocity) > 50:\n",
    "        explanation += \"  - High velocity, possible rapid movement or drone jerk.\\n\"\n",
    "    if np.linalg.norm(acceleration) > 50:\n",
    "        explanation += \"  - High acceleration, possibly due to a sudden change in direction or speed.\\n\"\n",
    "    \n",
    "    print(explanation)\n",
    "\n",
    "# Plotting the results using matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(deviation)), deviation, label=\"Deviation from Smoothed Path\")\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label=\"Anomaly Threshold\")\n",
    "\n",
    "# Highlight detected anomalies\n",
    "plt.scatter(anomaly_indices, deviation[anomaly_indices], color='red', label=\"Anomalies\")\n",
    "\n",
    "plt.xlabel(\"Frame Number\")\n",
    "plt.ylabel(\"Deviation (mm)\")\n",
    "plt.title(\"Drone Trajectory Deviation and Anomaly Detection\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy.signal import savgol_filter\n",
    "import time\n",
    "\n",
    "# Initialize the video capture\n",
    "cap = cv2.VideoCapture(0)  # Adjust for your video source or camera index\n",
    "\n",
    "# Initialize parameters\n",
    "previous_position = None\n",
    "previous_time = None\n",
    "trajectory_data = []\n",
    "\n",
    "def calculate_velocity_acceleration(new_position, previous_position, dt):\n",
    "    # Calculate velocity (distance per unit time)\n",
    "    velocity = np.array((new_position - previous_position) / dt)\n",
    "    \n",
    "    # Calculate acceleration if enough data points are available\n",
    "    if len(trajectory_data) > 1:\n",
    "        prev_velocity = trajectory_data[-1]['velocity']\n",
    "        acceleration = (velocity - prev_velocity) / dt\n",
    "    else:\n",
    "        acceleration = np.array([0, 0, 0])  # No acceleration for the first frame\n",
    "    \n",
    "    return velocity, acceleration\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Detect the drone in frame (Here, we assume some object detection mechanism is used)\n",
    "    # For this example, we’re simply tracking a specific color range\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # Assuming your drone is of a specific color (modify this range as necessary)\n",
    "    mask = cv2.inRange(hsv_frame, (40, 70, 70), (80, 255, 255))\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # If the drone is detected, calculate its position in 3D space\n",
    "    if contours:\n",
    "        # Assume largest contour is the drone\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        \n",
    "        # Dummy Z coordinate (replace with actual depth data from depth camera)\n",
    "        z = 1000  # Replace with depth information in mm\n",
    "        \n",
    "        # Convert (x, y, z) to millimeters based on camera calibration data (this part depends on your camera setup)\n",
    "        x_mm = x * conversion_factor_x\n",
    "        y_mm = y * conversion_factor_y\n",
    "        position = np.array([x_mm, y_mm, z])\n",
    "        \n",
    "        # Calculate time delta\n",
    "        current_time = time.time()\n",
    "        if previous_time:\n",
    "            dt = current_time - previous_time\n",
    "        else:\n",
    "            dt = 0\n",
    "        previous_time = current_time\n",
    "        \n",
    "        # Calculate velocity and acceleration\n",
    "        if previous_position is not None:\n",
    "            velocity, acceleration = calculate_velocity_acceleration(position, previous_position, dt)\n",
    "        else:\n",
    "            velocity, acceleration = np.array([0, 0, 0]), np.array([0, 0, 0])\n",
    "        \n",
    "        # Append data for trajectory analysis\n",
    "        trajectory_data.append({\n",
    "            'position': position,\n",
    "            'velocity': velocity,\n",
    "            'acceleration': acceleration,\n",
    "            'timestamp': current_time\n",
    "        })\n",
    "        \n",
    "        previous_position = position\n",
    "        \n",
    "        # Display tracking information\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Position (mm): {position}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    cv2.imshow(\"Drone Tracking\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Trajectory Analysis: smoothness, accuracy, precision\n",
    "positions = np.array([data['position'] for data in trajectory_data])\n",
    "\n",
    "# Smoothing trajectory data for analysis (e.g., Savitzky-Golay filter)\n",
    "smoothed_positions = savgol_filter(positions, window_length=5, polyorder=2, axis=0)\n",
    "\n",
    "# Analyze deviations or anomalies in smoothness, accuracy\n",
    "deviation = np.linalg.norm(positions - smoothed_positions, axis=1)\n",
    "anomalies = deviation > threshold  # Define a threshold for deviations\n",
    "\n",
    "print(\"Trajectory Analysis Complete.\")\n",
    "print(\"Detected Anomalies:\", np.where(anomalies)[0])  # Indices of anomaly frames\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
